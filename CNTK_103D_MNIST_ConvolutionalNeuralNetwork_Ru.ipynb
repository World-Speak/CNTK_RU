{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "29b9bd1d-766f-4422-ad96-de0accc1ce58"
    }
   },
   "source": [
    "# CNTK 103: Part D - Сверточная нейронная сеть с MNIST\n",
    "\n",
    "Мы предполагаем, что вы изучили CNTK 103 Part A CNTK 103 Part A (MNIST Data Loader).\n",
    "\n",
    "В этом уроке мы будем тренировать сверточную нейронную сеть (CNN) по данным MNIST. Используется API Python. Если вы ищете этот пример в BrainScript, посмотрите(https://github.com/Microsoft/CNTK/tree/release/2.2/Examples/Image/GettingStarted)\n",
    "\n",
    "## Введение\n",
    "\n",
    "[Сверточная нейронная сеть](https://en.wikipedia.org/wiki/Convolutional_neural_network) (CNN или ConvNet) является типом [feed-forward](https://en.wikipedia.org/wiki/Feedforward_neural_network) искусственная нейронная сеть, состоящая из нейронов, обладающих узнаваемыми весами и смещениями, очень похожей на обычные многослойные сети персептрона (MLP), введенные в 103C. CNN используют пространственный характер данных. В природе мы воспринимаем разные объекты по их форме, размеру и цвету. Например, объекты  обычно представляют собой ребра, углы / вершины (определенные двумя и более краями), цветовые пятна и т. Д. Эти примитивы часто идентифицируются с использованием разных детекторов (например, детектирование края, детектор цвета) или комбинация взаимодействующих детекторов для облегчения интерпретации изображений (классификация объектов, определение области, описание и т. д.) в задачах, связанных с реальным миром. Эти детекторы также известны как фильтры. Convolution - это математический оператор, который принимает изображение и фильтр в качестве входных данных и производит отфильтрованный вывод  (представляющий собой  углы, цвета и т. д. во входном изображении).  Исторически эти фильтры представляют собой набор весов, которые часто обрабатывались вручную или моделировались математическими функциями (например [Gaussian](https://en.wikipedia.org/wiki/Gaussian_filter) / [Laplacian](http://homepages.inf.ed.ac.uk/rbf/HIPR2/log.htm) / [Canny](https://en.wikipedia.org/wiki/Canny_edge_detector) фильтрами).  Выходы фильтра отображаются через функции нелинейной активации, имитирующие человеческие клетки мозга, называемые [нейронами](https://en.wikipedia.org/wiki/Neuron).\n",
    "\n",
    "Сверточные сети предоставляют механизм для изучения этих фильтров непосредственно из данных вместо явных математических моделей и, как было установлено, превосходят (в реальных задачах) по сравнению с исторически создаваемыми фильтрами. В сверточных сетях основное внимание уделяется изучению весов фильтров, а не обучению индивидуально полностью подключенных пар (между входами и выходами) весов. Таким образом, количество весов для обучения уменьшается по сравнению с традиционными сетями MLP из предыдущих уроков. В сверточной сети обочается несколько фильтров, от нескольких отдельных цифр до нескольких тысяч в зависимости от сложности сети.\n",
    "\n",
    "Было показано, что многие из примитивов CNN имеют концептуально параллельные компоненты в зрительной коре головного мозга  [visual cortex](https://en.wikipedia.org/wiki/Visual_cortex). Группа нейронов в зрительной коре выделяет ответы при стимуляции. Эта область известна как восприимчивое поле  (RF).  Эквивалентно, в сверточной сети область ввода, соответствующая размерам фильтра, может рассматриваться как восприимчивое поле. Глубокие  CNNs или ConvNets сети (такие как [AlexNet](https://en.wikipedia.org/wiki/AlexNet), [VGG](https://arxiv.org/abs/1409.1556), [Inception](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf), [ResNet](https://arxiv.org/pdf/1512.03385v1.pdf)) используются для различных [computer vision](https://en.wikipedia.org/wiki/Computer_vision) задач.  \n",
    "\n",
    "В этом уроке мы используем операцию свертки и познакомимся с различными параметрами в CNN.\n",
    "\n",
    "**Проблема**:\n",
    "Как и в CNTK 103C, мы продолжим работу над той же проблемой распознавания цифр в данных MNIST. Данные MNIST содержат рукописные цифры с небольшим фоновым шумом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-72e2407a94ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Рисунок 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m\"http://3.bp.blogspot.com/_UpN7DfJA0j4/TJtUBWPk0SI/AAAAAAAAABY/oWPMtmqJn3k/s1600/mnist_originals.png\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "# Рисунок 1\n",
    "Image(url= \"http://3.bp.blogspot.com/_UpN7DfJA0j4/TJtUBWPk0SI/AAAAAAAAABY/oWPMtmqJn3k/s1600/mnist_originals.png\", width=200, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Цель**:\n",
    "Наша цель - подготовить классификатор, который будет идентифицировать цифры в наборе данных MNIST. \n",
    "\n",
    "**Подход**:\n",
    "\n",
    "Используются те же 5 этапов, которые мы использовали в предыдущем учебнике: чтение данных, предварительная обработка данных, создание модели, изучение параметров модели и оценка  (a.k.a. testing/prediction) модели. \n",
    "- Чтение данных: мы будем использовать CNTK Text reader \n",
    "- Предварительная обработка данных: Поясняется в части A.\n",
    "\n",
    "В этом уроке мы будем экспериментировать с двумя моделями с различными архитектурными компонентами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "138d1a78-02e2-4bd6-a20e-07b83f303563"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cntk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f69468920d36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcntk\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcntk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mcntk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_device_from_pytest_env\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# (требуется только для нашей системы сборки)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cntk'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function # Используйте определение функции  версии (скажем 3.x from 2.7 interpreter)\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (требуется только для нашей системы сборки)\n",
    "C.cntk_py.set_fixed_random_seed(1) # перемешаем, чтобы примеры не повторялись\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение данных\n",
    "\n",
    "В этом разделе мы используем данные, сгенерированные в CNTK 103 Part A (MNIST Data Loader).\n",
    "\n",
    "Мы используем данные MNIST, загруженные с помощью ноутбука  CNTK_103A_MNIST_DataLoader. . Набор данных содержит 60 000 обучающих изображений и 10 000 тестовых изображений, каждое изображение которых составляет 28 х 28 пикселей. Таким образом, количество функций равно 784 (= 28 x 28 пикселей), 1 на пиксель. Переменная  `num_output_classes` установлена в 10, соответствующая количеству цифр (0-9) в наборе данных.\n",
    "\n",
    "В предыдущих уроках, как показано ниже, мы всегда сглаживали входное изображение в вектор. С сверточными сетями мы не сглаживаем изображение таким образом.\n",
    "\n",
    "![](https://www.cntk.ai/jup/cntk103a_MNIST_input.png)\n",
    "\n",
    "**Размеры входного сигнала**:  \n",
    "\n",
    "В сверточных сетях для изображений входные данные часто формируются как трехмерная матрица (количество каналов, ширина изображения, высота), что сохраняет пространственную взаимосвязь между пикселями. На рисунке выше изображение MNIST представляет собой данные с одним каналом (в оттенках серого), поэтому размер ввода задается как (1, ширина изображения, высота изображения).\n",
    "\n",
    "![](https://www.cntk.ai/jup/cntk103d_rgb.png)\n",
    "\n",
    "Естественные цветные изображения часто представлены в цветовых каналах Red-Green-Blue (RGB). Входной размер таких изображений задается как  (3, ширина изображения, высота изображения). Если входные данные RGB являются объемным сканированием с шириной объема, объемом и глубиной объема, представляющей 3 оси, формат входных данных будет определяться  из 4 значений (3, объемная ширина, высота объема, глубина объема). Таким образом, CNTK позволяет специфицировать входные изображения в произвольном многомерном пространстве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Определение размеров данных\n",
    "input_dim_model = (1, 28, 28)    # изображения 28 x 28 с 1 каналом цвета (серый)\n",
    "input_dim = 28*28                # используемые читателями для обработки входных данных в виде вектора\n",
    "num_output_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Формат данных** Данные хранятся на нашей локальной машине в формате CNTK CTF. Формат CTF представляет собой простой текстовый формат, который содержит набор выборок с каждым образцом, содержащим набор именованных полей и их данных. Для наших данных MNIST каждый образец содержит 2 поля: метки и функции, отформатированные как:\n",
    "\n",
    "    |labels 0 0 0 1 0 0 0 0 0 0 |features 0 255 0 123 ... \n",
    "                                                  (784 integers each representing a pixel gray level)\n",
    "    \n",
    "В этом уроке мы будем использовать пиксели изображения, соответствующие целочисленному потоку с именем \"features\".  Мы определяем функцию  `create_reader` для чтения данных обучения и тестирования с помощью [CTF deserializer](https://cntk.ai/pythondocs/cntk.io.html#cntk.io.CTFDeserializer).\n",
    "\n",
    "Метки [1-hot](https://en.wikipedia.org/wiki/One-hot) зокодированы (метка, представляющая класс вывода 3, становится `0001000000` , так как у нас есть 10 классов для 10 возможных цифр) , где первый индекс соответствует цифре `0` , а последний соответствует цифре `9`.\n",
    "\n",
    "![](https://www.cntk.ai/jup/cntk103a_onehot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Прочтите текст в формате CTF (как упоминалось выше), используя десериализатор CTF из файла\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    \n",
    "    ctf = C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "          labels=C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "          features=C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)))\n",
    "                          \n",
    "    return C.io.MinibatchSource(ctf,\n",
    "        randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is data\\MNIST\n"
     ]
    }
   ],
   "source": [
    "# Убедитесь, что доступны учебные и тестовые данные.\n",
    "# Мы выполняем поиск в двух местах в наборе инструментов для кэшированного набора данных MNIST.\n",
    "\n",
    "data_found=False # Флаг, указывающий, обнаружены ли данные train/test data found  в локальном кеше\n",
    "for data_dir in [os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\"),\n",
    "                 os.path.join(\"data\", \"MNIST\")]:\n",
    "    \n",
    "    train_file=os.path.join(data_dir, \"Train-28x28_cntk_text.txt\")\n",
    "    test_file=os.path.join(data_dir, \"Test-28x28_cntk_text.txt\")\n",
    "    \n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found=True\n",
    "        break\n",
    "        \n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing CNTK 103 Part A\")\n",
    "    \n",
    "print(\"Data directory is {0}\".format(data_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели CNN\n",
    "\n",
    "CNN - это прямая сеть, состоящая из множества слоев таким образом, что выход одного слоя становится входным для следующего слоя (аналогично MLP). В MLP все возможные пары входных пикселей соединены с выходными узлами и с каждой парой, имеющей вес, что приводит к комбинаторному изменению параметров, подлежащих изучению, а также к увеличению возможности переобучения ([детали](http://cs231n.github.io/neural-networks-1/)).  Уровни свертки используют пространственное расположение пикселей и изучают несколько фильтров, которые значительно уменьшают количество параметров в сети ([детали](http://cs231n.github.io/convolutional-networks/)). Размер фильтра является параметром слоя свертки. \n",
    "\n",
    "В этом разделе мы введем основы операций свертки. Мы показываем иллюстрации в контексте RGB-изображений (3 канала), хотя данные MNIST, которые мы используем в этом учебнике, представляют собой изображение в оттенках серого (один канал).\n",
    "\n",
    "![](https://www.cntk.ai/jup/cntk103d_rgb.png)\n",
    "\n",
    "### Сверточный слой\n",
    "\n",
    "Слой свертки представляет собой набор фильтров. Каждый фильтр определяется весовой (**W**) матрицей и смещением ($b$).\n",
    "\n",
    "![](https://www.cntk.ai/jup/cntk103d_filterset_v2.png)\n",
    "\n",
    "Эти фильтры сканируются через изображение, выполняющее точечный проход между весами и соответствующим входным значением ($x$). Значение смещения добавляется к выходу точечного произведения, и полученная сумма необязательно отображается через функцию активации. Этот процесс проиллюстрирован в следующей анимации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c5d233ba98a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"https://www.cntk.ai/jup/cntk103d_conv2d_final.gif\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "Image(url=\"https://www.cntk.ai/jup/cntk103d_conv2d_final.gif\", width= 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уровни свертки включают следующие основные функции:\n",
    "\n",
    "   - Вместо того, чтобы полностью подключаться ко всем парам входных и выходных узлов, каждый узел свертки **локально подключенного - locally-connected** к подмножеству входных узлов, локализованных в меньшей области ввода, также называемой восприимчивым полем (RF). На рисунке выше показаны небольшие 3 x 3 области изображения в качестве области сканирования. В случае с RGB изображением будет иметь три таких 3 x 3 области, по одному из трех цветовых каналов. \n",
    "   \n",
    "   \n",
    "   - Вместо того, чтобы иметь один набор весов (как в плотном слое), сверточные слои имеют несколько наборов (показаны на рисунке с несколькими цветами), называемые **фильтрами - filters**. Каждый фильтр обнаруживает функции в каждом возможном RF во входном изображении. Вывод свертки представляет собой набор подслоев `n`(показано в анимации ниже), где `n` количество фильтров (см. Приведенный выше рисунок).  \n",
    "   \n",
    "     \n",
    "   - Внутри подуровня вместо каждого узла, имеющего собственный набор весов, один набор **общих весов - shared weights**  используется всеми узлами в этом подуровне. Это уменьшает количество параметров, подлежащих изучению, и, таким образом, перерабатывает. Это также открывает двери для нескольких аспектов глубокого обучения, которые позволили построить очень практичные решения:\n",
    "    - Обработка больших изображений (например, 512 x 512)\n",
    "    - Попытка увеличить размер фильтра (соответствует более крупному RF), например, 11 x 11\n",
    "    - Изучение большего количества фильтров (скажем 128)\n",
    "    - Исследование более глубоких архитектур (более 100 слоев)\n",
    "    - Обеспечить переводную инвариантность (возможность распознавания функции независимо от того, где они появляются на изображении). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры Strides и Pad\n",
    "\n",
    "**Как размещаются фильтры?** В общем, фильтры расположены в перекрывающихся областях слева направо и сверху вниз. Каждый уровень свертки имеет параметр для указания `filter_shape`, определяющий ширину и высоту фильтра в случае большинства естественных изображений. Существует параметр (`strides`) , который управляет тем, как далеко перейти вправо при перемещении фильтров через несколько RF-строк в ряд, и как далеко отступить при переходе к следующей строке. Логический параметр `pad` управляет, если вход должен быть дополнен по краям, чтобы обеспечить полную разбивку RF на границах. \n",
    "\n",
    "Анимация выше показывает результаты с помощью `filter_shape` = (3, 3), `strides` = (2, 2) и `pad` = False. Две приведенные ниже анимации показывают результаты, когда для параметра `pad` становлено значение True. Во-первых, с шагом 2 и вторым с шагом 1.\n",
    "\n",
    "Примечание: форма вывода (the teal layer)  отличается между двумя настройками шага. Множество ваших решений о выборе площадки и значения шага  основаны на форме требуемого уровня вывода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With stride = 2\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'display' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-93fe79ba8452>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'display' is not defined"
     ]
    }
   ],
   "source": [
    "# Графические изображения с шагом 2 и 1 с включенным дополнением\n",
    "images = [(\"https://www.cntk.ai/jup/cntk103d_padding_strides.gif\" , 'With stride = 2'),\n",
    "          (\"https://www.cntk.ai/jup/cntk103d_same_padding_no_strides.gif\", 'With stride = 1')]\n",
    "\n",
    "for im in images:\n",
    "    print(im[1])\n",
    "    display(Image(url=im[0], width=200, height=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Построение наших моделей CNN\n",
    "\n",
    "В этом учебнике CNN мы сначала определяем два контейнера. Один для входного изображения MNIST, а второй - метки, соответствующие 10 цифрам. При чтении данных считыватель автоматически отображает 784 пикселя на изображение в форму, определенную  `input_dim_model` (в этом примере она установлена (1, 28, 28))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d8e348d12f10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dim_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_variable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "x = C.input_variable(input_dim_model)\n",
    "y = C.input_variable(num_output_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первая построенная нами модель представляет собой простую сеть сверток. Здесь мы имеем два сверточных слоя. Поскольку наша задача - обнаружить 10 цифр в базе данных MNIST, выход сети должен быть вектором длиной 10, 1, соответствующим каждой цифре. Это достигается путем проецирования вывода последнего сверточного слоя с использованием плотного слоя с выходом  `num_output_classes`. Мы видели это раньше с логистической регрессией и MLP, где функции были сопоставлены с количеством классов в конечном слое. Также обратите внимание, что поскольку мы будем использовать операцию `softmax` которая комбинируется с функцией потери `cross entropy` во время тренировки (см. Несколько ячеек ниже), последний плотный слой не имеет связанной с ним функции активации.\n",
    "\n",
    "На следующем рисунке показана модель, которую мы собираемся построить. Обратите внимание, что параметры в приведенной ниже модели должны быть экспериментированы. Они часто называют сетевыми гиперпараметрами. Увеличение формы фильтра приводит к увеличению количества параметров модели, увеличивает время вычисления и помогает модели лучше соответствовать данным. Тем не менее, существует риск [overfitting - переобучения](https://en.wikipedia.org/wiki/Overfitting).  Как правило, количество фильтров в более глубоких слоях больше, чем количество фильтров в слоях перед ними. Мы выбрали 8, 16 для первого и второго слоев соответственно. С этими гиперпараметрами следует экспериментировать во время построения модели.\n",
    "\n",
    "![](https://www.cntk.ai/jup/cntk103d_convonly2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция построения модели\n",
    "\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init=C.glorot_uniform(), activation=C.relu):\n",
    "            h = features\n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=8, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='first_conv')(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=16, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='second_conv')(h)\n",
    "            r = C.layers.Dense(num_output_classes, activation=None, name='classify')(h)\n",
    "            return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим экземпляр модели и проверим различные компоненты модели. `z` будет использоваться для представления вывода сети. В этой модели мы используем функцию активации `relu` . \n",
    "Примечание: использование `C.layers.default_options`  - это элегантный способ создания сжатых моделей. Это ключ к минимизации ошибок моделирования, что экономит драгоценное время отладки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-e71910d8ea89>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Создать модель\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Печать выходных shapes / parameters различных компонентов\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Output Shape of the first convolution layer:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst_conv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# Создать модель\n",
    "z = create_model(x)\n",
    "\n",
    "# Печать выходных shapes / parameters различных компонентов\n",
    "print(\"Output Shape of the first convolution layer:\", z.first_conv.shape)\n",
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понимание числа параметров модели, которые должны быть оценены, является ключом к глубокому обучению, поскольку существует прямая зависимость от объема данных, который требуется иметь. Вам нужно больше данных для модели, которая имеет большее количество параметров для предотвращения переобучения. Другими словами, при фиксированном объеме данных необходимо ограничить количество параметров. Между объемом данных, требуемым для модели, нет золотого правила. Тем не менее, есть способы повысить производительность обучения модели с помощью [data augmentation](https://deeplearningmania.quora.com/The-Power-of-Data-Augmentation-2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d446ced2b1ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Количество параметров в сети\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_number_of_parameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "# Количество параметров в сети\n",
    "C.logging.log_number_of_parameters(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Понимание параметров**:\n",
    "\n",
    "\n",
    "Наша модель имеет 2 слоя свертки, каждый из которых имеет вес и смещение. Это добавляет до 4 тензоров параметров. Кроме того, плотный слой имеет тензоры веса и смещения. Таким образом, 6 параметрических тензоров.\n",
    "\n",
    "Давайте теперь подсчитаем количество параметров:\n",
    "- *Первый слой свертки*: Tимеется 8 фильтров каждого размера (1 x 5 x 5), где 1 - количество каналов на входном изображении. Это добавляет до 200 значений в весовой матрице и 8 значений смещения.\n",
    "\n",
    "\n",
    "- *Второй уровень свертки*: имеется 16 фильтров каждого размера (8 x 5 x 5), где 8 - количество каналов на входе ко второму слою (= выход первого слоя). Это добавляет до 3200 значений в весовой матрице и 16 значений смещения.\n",
    "\n",
    "\n",
    "- *Последний плотный слой*: есть 16 x 7 x 7 входных значений, и он производит 10 выходных значений, соответствующих 10 цифрам в наборе данных MNIST. Это соответствует (16 x 7 x 7) x 10 весовых значений и 10 значений смещения.\n",
    "\n",
    "Что дает модели 11274 параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка знаний**: Соответствует ли плотная форма слоя задаче (классификация цифр MNIST)?\n",
    "\n",
    "** Самостоятельная работа **\n",
    "- Попробуйте изменить формы и параметры различных сетевых слоев,\n",
    "- Запишите ошибку обучения, которую вы получите с помощью функции `relu` в качестве функции активации,\n",
    "- Теперь измените на `sigmoid` ак функцию активации и посмотрите, можете ли вы улучшить свою ошибку обучения.\n",
    "\n",
    "*Дополнительно*: Различные поддерживаемые функции активации [взять здесь](https://cntk.ai/pythondocs/cntk.layers.layers.html#cntk.layers.layers.Activation). Какая функция активации дает наименьшую ошибку обучения?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Параметры модели обучения\n",
    "\n",
    "Как и в предыдущем учебнике, мы используем функциюe `softmax` для сопоставления накопленных доказательств или активации с распределением вероятности по классам (подробнее [softmax function](http://cntk.ai/pythondocs/cntk.ops.html#cntk.ops.softmax) и другие функции активации [activation](https://cntk.ai/pythondocs/cntk.layers.layers.html#cntk.layers.layers.Activation) )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "\n",
    "Подобно CNTK 102, мы минимизируем кросс-энтропию - \"cross-entropy\" между меткой и прогнозируемой вероятностью сетью. Если эта терминология звучит странно для вас, обратитесь к CNTK 102 для обучения. Поскольку мы собираемся построить более одной модели, мы создадим несколько вспомогательных функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_criterion_function(model, labels):\n",
    "    loss = C.cross_entropy_with_softmax(model, labels)\n",
    "    errs = C.classification_error(model, labels)\n",
    "    return loss, errs # (model, labels) -> (loss, error metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее нам понадобится вспомогательная функция для обучения модели. Сначала создадим дополнительные вспомогательные функции, которые понадобятся для визуализации различных функций, связанных с обучением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Определите функцию полезности для вычисления скользящей средней суммы.\n",
    "# Более эффективная реализация возможна с помощью функции np.cumsum()\n",
    "def moving_average(a, w=5):\n",
    "    if len(a) < w:\n",
    "        return a[:]    # Нужно отправить копию массива\n",
    "    return [val if idx < w else sum(a[(idx-w):idx])/w for idx, val in enumerate(a)]\n",
    "\n",
    "\n",
    "# Определяет утилиту, которая печатает ход обучения\n",
    "def print_training_progress(trainer, mb, frequency, verbose=1):\n",
    "    training_loss = \"NA\"\n",
    "    eval_error = \"NA\"\n",
    "\n",
    "    if mb%frequency == 0:\n",
    "        training_loss = trainer.previous_minibatch_loss_average\n",
    "        eval_error = trainer.previous_minibatch_evaluation_average\n",
    "        if verbose: \n",
    "            print (\"Minibatch: {0}, Loss: {1:.4f}, Error: {2:.2f}%\".format(mb, training_loss, eval_error*100))\n",
    "        \n",
    "    return mb, training_loss, eval_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настройка обучения\n",
    "\n",
    "В предыдущих уроках мы описали понятия функции `loss` , оптимизаторы или  [learners](https://cntk.ai/pythondocs/cntk.learners.html) и связанные с ними механизмы, необходимые для обучения модели. Пожалуйста, обратитесь к предыдущим учебным пособиям, чтобы получить описание этих концепций. В этом уроке мы комбинируем обучение модели и тестирование в вспомогательной функции ниже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_test(train_reader, test_reader, model_func, num_sweeps_to_train_with=10):\n",
    "    \n",
    "    # Выполнить функцию модели; x - переменная ввода (функции)\n",
    "    # Мы будем масштабировать пиксели входного изображения в диапазоне 0-1, разделив все входное значение на 255.\n",
    "    model = model_func(x/255)\n",
    "    \n",
    "    # Выполнить функцию потери и ошибки\n",
    "    loss, label_error = create_criterion_function(model, y)\n",
    "    \n",
    "    # Iсоздать экземпляр объекта тренера для обучения модели\n",
    "    learning_rate = 0.2\n",
    "    lr_schedule = C.learning_rate_schedule(learning_rate, C.UnitType.minibatch)\n",
    "    learner = C.sgd(z.parameters, lr_schedule)\n",
    "    trainer = C.Trainer(z, (loss, label_error), [learner])\n",
    "    \n",
    "    # Инициализация параметров для тренера\n",
    "    minibatch_size = 64\n",
    "    num_samples_per_sweep = 60000\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) / minibatch_size\n",
    "    \n",
    "    # Сопоставьте потоки данных со входом и метками.\n",
    "    input_map={\n",
    "        y  : train_reader.streams.labels,\n",
    "        x  : train_reader.streams.features\n",
    "    } \n",
    "    \n",
    "    # Раскоммент ниже для более подробного ведения журнала\n",
    "    training_progress_output_freq = 500\n",
    "     \n",
    "    # Запустить таймер\n",
    "    start = time.time()\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_train)):\n",
    "        #Прочитайте мини-пакет из файла данных обучения\n",
    "        data=train_reader.next_minibatch(minibatch_size, input_map=input_map) \n",
    "        trainer.train_minibatch(data)\n",
    "        print_training_progress(trainer, i, training_progress_output_freq, verbose=1)\n",
    "     \n",
    "    # Время обучения печати\n",
    "    print(\"Training took {:.1f} sec\".format(time.time() - start))\n",
    "    \n",
    "    # Проверить модель\n",
    "    test_input_map = {\n",
    "        y  : test_reader.streams.labels,\n",
    "        x  : test_reader.streams.features\n",
    "    }\n",
    "\n",
    "    # Данные испытаний для обученной модели\n",
    "    test_minibatch_size = 512\n",
    "    num_samples = 10000\n",
    "    num_minibatches_to_test = num_samples // test_minibatch_size\n",
    "\n",
    "    test_result = 0.0   \n",
    "\n",
    "    for i in range(num_minibatches_to_test):\n",
    "    \n",
    "        # Мы загружаем тестовые данные пакетами, указанными test_minibatch_size\n",
    "        # EКаждая точка данных в minibatch представляет собой изображение цифры  \n",
    "        # MNIST размером 784 с одним пикселем на измерение, которое мы будем \n",
    "        # кодировать / декодировать с помощью обучаемой модели.\n",
    "        data = test_reader.next_minibatch(test_minibatch_size, input_map=test_input_map)\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        test_result = test_result + eval_error\n",
    "\n",
    "    # Среднее значение ошибки оценки всех тестовых minibatches\n",
    "    print(\"Average test error: {0:.2f}%\".format(test_result*100 / num_minibatches_to_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск тренера и тестовой модели\n",
    "\n",
    "Теперь мы готовы тренировать нашу сверточную нейронную сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-0055cec51ad8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreader_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdo_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-0055cec51ad8>\u001b[0m in \u001b[0;36mdo_train_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdo_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mreader_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mreader_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "def do_train_test():\n",
    "    global z\n",
    "    z = create_model(x)\n",
    "    reader_train = create_reader(train_file, True, input_dim, num_output_classes)\n",
    "    reader_test = create_reader(test_file, False, input_dim, num_output_classes)\n",
    "    train_test(reader_train, reader_test, z)\n",
    "    \n",
    "do_train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что средняя ошибка теста очень сопоставима с нашей ошибкой обучения, указывающей на то, что наша модель имеет хорошую ошибку  \"out of sample\" error a.k.a. [generalization error](https://en.wikipedia.org/wiki/Generalization_error). Это означает, что наша модель может очень эффективно справляться с ранее невидимыми наблюдениями (во время учебного процесса). Это ключ, чтобы избежать [преобучения - overfitting](https://en.wikipedia.org/wiki/Overfitting).\n",
    "\n",
    "Давайте посмотрим, что является значением некоторых параметров сети. Мы проверим значение смещения выходного плотного слоя. Раньше это было все 0. Теперь вы видите ненулевые значения, указывающие, что параметры модели были обновлены во время обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-10ba60a8ff4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Bias value of the last dense layer:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassify\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'z' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Bias value of the last dense layer:\", z.classify.b.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск оценки / прогнозирования\n",
    "До сих пор мы имеем дело с совокупными мерами ошибки. Возьмем теперь вероятности, связанные с отдельными точками данных. Для каждого наблюдения функция `eval` возвращает распределение вероятности по всем классам. Классификатор обучается распознавать цифры, поэтому имеет 10 классов. Сначала проложим сетевой выход через функцию `softmax`. Это сопоставляет агрегированные активации по сети с вероятностями по 10 классам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'C' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-373365e40f5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'C' is not defined"
     ]
    }
   ],
   "source": [
    "out = C.softmax(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратимся к небольшому образцу из тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Прочтите данные для оценки\n",
    "reader_eval=create_reader(test_file, False, input_dim, num_output_classes)\n",
    "\n",
    "eval_minibatch_size = 25\n",
    "eval_input_map = {x: reader_eval.streams.features, y:reader_eval.streams.labels} \n",
    "\n",
    "data = reader_eval.next_minibatch(eval_minibatch_size, input_map=eval_input_map)\n",
    "\n",
    "img_label = data[y].asarray()\n",
    "img_data = data[x].asarray()\n",
    "\n",
    "# reshape img_data to: M x 1 x 28 x 28 to be compatible with model\n",
    "img_data = np.reshape(img_data, (eval_minibatch_size, 1, 28, 28))\n",
    "\n",
    "predicted_label_prob = [out.eval(img_data[i]) for i in range(len(img_data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_label_prob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-d9a4dbfded41>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Найдите индекс с максимальным значением как для предсказанной, так и для основной истины\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_label_prob\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_label_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgtlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_label\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_label\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predicted_label_prob' is not defined"
     ]
    }
   ],
   "source": [
    "# Найдите индекс с максимальным значением как для предсказанной, так и для основной истины\n",
    "pred = [np.argmax(predicted_label_prob[i]) for i in range(len(predicted_label_prob))]\n",
    "gtlabel = [np.argmax(img_label[i]) for i in range(len(img_label))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gtlabel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-9f61de49700b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Label    :\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgtlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Predicted:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gtlabel' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Label    :\", gtlabel[:25])\n",
    "print(\"Predicted:\", pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте визуализируем некоторые результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-2012d5a968bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Печать случайного изображения\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msample_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_number\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"gray_r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'off'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Печать случайного изображения\n",
    "sample_number = 5\n",
    "plt.imshow(img_data[sample_number].reshape(28,28), cmap=\"gray_r\")\n",
    "plt.axis('off')\n",
    "\n",
    "img_gt, img_pred = gtlabel[sample_number], pred[sample_number]\n",
    "print(\"Image Label: \", img_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Слой объединения\n",
    "\n",
    "Часто в некоторых случаях необходимо контролировать количество параметров, особенно при наличии глубоких сетей. Для каждого слоя выходного уровня свертки (каждый слой соответствует выходному сигналу фильтра), у него может быть слой объединения. Уровни объединения обычно вводятся в:\n",
    "- Уменьшите размерность предыдущего слоя (ускорение сети),\n",
    "- Делает модель более толерантной к изменениям в местоположении объекта на изображении. Например, даже когда цифра смещается в одну сторону изображения вместо того, чтобы быть посередине, классификатор будет выполнять задачу классификации хорошо.\n",
    "\n",
    "Расчет на узле объединения намного проще, чем обычный упреждающий узел. Он не имеет веса, смещения или функции активации. Он использует простую функцию агрегации (например, max или average) для вычисления ее вывода. Наиболее часто используемой функцией является  \"max\" - максимальный узел объединения просто выводит максимум входных значений, соответствующих позиции фильтра на входе. На рисунке ниже показаны входные значения в области 4 x 4. Максимальный размер окна объединения составляет 2 x 2 и начинается с верхнего левого угла. Максимальное значение в окне становится выходом области. Каждый раз, когда модель сдвигается на величину, указанную параметром шага (как показано на рисунке ниже), и максимальная операция объединения повторяется. \n",
    "![maxppool](https://cntk.ai/jup/201/MaxPooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой альтернативой является средний пул, который испускает это среднее значение вместо максимального значения. Два разных пула кластера суммируются в анимации ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max pooling\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'display' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-6e1f6d6257ba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'display' is not defined"
     ]
    }
   ],
   "source": [
    "# Графические изображения с шагом 2 и 1 с включенным дополнением\n",
    "images = [(\"https://www.cntk.ai/jup/c103d_max_pooling.gif\" , 'Max pooling'),\n",
    "          (\"https://www.cntk.ai/jup/c103d_average_pooling.gif\", 'Average pooling')]\n",
    "\n",
    "for im in images:\n",
    "    print(im[1])\n",
    "    display(Image(url=im[0], width=300, height=300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типичная сеть свертки\n",
    "\n",
    "![](http://www.cntk.ai/jup/conv103d_mnist-conv-mp.png)\n",
    "\n",
    "Типичный CNN содержит набор чередующихся слоев свертки и объединения, за которыми следует плотный выходной уровень для классификации. Вы найдете варианты этой структуры во многих классических глубоких сетях (VGG, AlexNet и т.д.). Это контрастирует с сетью MLP, которую мы использовали в CNTK_103C, которая состояла из 2 плотных слоев, за которыми следовал плотный выходной уровень.\n",
    "\n",
    "Иллюстрации представлены в контексте двумерных (2D) изображений, но концепция и компоненты CNTK могут работать с любыми размерными данными. На приведенной выше схеме показан 2 слоя свертки и 2 слоя с максимальным пулом. Типичная стратегия заключается в увеличении количества фильтров в более глубоких слоях при уменьшении пространственного размера каждого промежуточного слоя."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание: Создайте сеть с помощью MaxPooling\n",
    "\n",
    "Типичные сверточные сети имеют чередующиеся свертки и максимальные уровни пулов. В предыдущей модели был только слой свертки. В этом разделе вы создадите модель со следующей архитектурой.\n",
    "\n",
    "![](https://www.cntk.ai/jup/cntk103d_conv_max2.png)\n",
    "\n",
    "Для достижения этой цели вы будете использовать функцию CNTK [MaxPooling](https://cntk.ai/pythondocs/cntk.layers.layers.html#cntk.layers.layers.MaxPooling) . Вы отредактируете функцию `create_model` ниже и добавьте операцию.\n",
    "\n",
    "Подсказка: мы предлагаем решение для нескольких ячеек ниже. Не смотрите вперед и старайтесь сначала добавить слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Изменить эту модель\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init = C.glorot_uniform(), activation = C.relu):\n",
    "            h = features\n",
    "            \n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=8, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='first_conv')(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=16, \n",
    "                                       strides=(2,2), \n",
    "                                       pad=True, name='second_conv')(h)\n",
    "            r = C.layers.Dense(num_output_classes, activation = None, name='classify')(h)\n",
    "            return r\n",
    "        \n",
    "# do_train_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Вопрос**: Сколько у нас параметров в модели с MaxPooling и Convolution? Какая из двух моделей дает более низкий коэффициент ошибок?\n",
    "\n",
    "\n",
    "**Самостоятельная работа**\n",
    "- Помогает ли использование LeakyRelu повысить коэффициент ошибок?\n",
    "- Какой процент параметра делает последний плотный слой вкладом w.r.t. общее число параметров для (а) чисто двух сверточных слоев и (б) чередующихся 2 сверточных и максимальных слоев   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-620d3fcad22f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mdo_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-0055cec51ad8>\u001b[0m in \u001b[0;36mdo_train_test\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdo_train_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mglobal\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mreader_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mreader_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_output_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "# функция построения модели\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init = C.layers.glorot_uniform(), activation = C.relu):\n",
    "            h = features\n",
    "            \n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=8, \n",
    "                                       strides=(1,1), \n",
    "                                       pad=True, name=\"first_conv\")(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(2,2), \n",
    "                                    strides=(2,2), name=\"first_max\")(h)\n",
    "            h = C.layers.Convolution2D(filter_shape=(5,5), \n",
    "                                       num_filters=16, \n",
    "                                       strides=(1,1), \n",
    "                                       pad=True, name=\"second_conv\")(h)\n",
    "            h = C.layers.MaxPooling(filter_shape=(3,3), \n",
    "                                    strides=(3,3), name=\"second_max\")(h)\n",
    "            r = C.layers.Dense(num_output_classes, activation = None, name=\"classify\")(h)\n",
    "            return r\n",
    "        \n",
    "do_train_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
