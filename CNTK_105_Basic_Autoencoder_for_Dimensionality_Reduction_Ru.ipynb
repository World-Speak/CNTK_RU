{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNTK 105: Базовый автокодер (AE) с данными MNIST\n",
    "\n",
    "**Предпосылки**: Мы предполагаем, что вы успешно загрузили данные MNIST, заполнив учебник под названием CNTK_103A_MNIST_DataLoader.ipynb.\n",
    "\n",
    "\n",
    "## Введение\n",
    "\n",
    "В этом уроке мы познакомим вас с основами [Autoencoders](https://en.wikipedia.org/wiki/Autoencoder). Автокодер - это искусственная нейронная сеть, используемая для неконтролируемого изучения эффективных кодировок. Другими словами, они используются для сжатия данных с потерями, которые изучаются автоматически вместо того, чтобы полагаться на человеческие инженерные функции. Целью автокодирования является изучение представления (кодирования) набора данных, как правило, с целью уменьшения размерности. \n",
    "\n",
    "Автокодеры очень специфичны для набора данных и не отличаются от стандартных кодеков, таких как JPEG, MPEG-кодированные кодировки. После того, как информация закодирована и декодируется до исходных измерений, в процессе теряется некоторая информация. Учитывая, что эти кодировки специфичны для данных, автокодеры не используются для сжатия. Тем не менее, есть две области, где автокодеры были очень эффективными: уменьшение шума и уменьшение размерности.\n",
    "\n",
    "Автокендеры привлекают внимание, поскольку они давно считаются потенциальным подходом к неконтролируемому обучению. Поистине неконтролируемые подходы подразумевают изучение полезных представлений без необходимости использования меток. Автокодеры попадают под самоконтролируемое обучение, конкретный экземпляр контролируемого обучения, где цели генерируются из входных данных. \n",
    "\n",
    "**Цель** \n",
    "\n",
    "Наша цель состоит в том, чтобы обучить автокодер, который сжимает MNIST цифру изображения до вектора меньшего размера, а затем восстанавливает изображение. Данные MNIST содержат рукописные цифры с небольшим фоновым шумом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://cntk.ai/jup/MNIST-image.jpg\" width=\"300\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Рисунок 1\n",
    "Image(url=\"http://cntk.ai/jup/MNIST-image.jpg\", width=300, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы будем использовать [MNIST рукописные цифры](https://en.wikipedia.org/wiki/MNIST_database), чтобы показать, как изображения могут быть закодированы и декодированы (восстановлены) с использованием сетей прямой пересылки. Мы визуализируем оригинальные и восстановленные изображения. Мы проиллюстрируем сеть подачи вперед на основе двух автокодеров: простого и глубокого автокодирования. Более продвинутые автокодеры будут рассмотрены в будущих учебниках серии 200."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the relevant modules\n",
    "from __future__ import print_function # Use a function definition from future version (say 3.x from 2.7 interpreter)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Import CNTK \n",
    "import cntk as C\n",
    "import cntk.tests.test_utils\n",
    "cntk.tests.test_utils.set_device_from_pytest_env() # (only needed for our build system)\n",
    "C.cntk_py.set_fixed_random_seed(1) # fix a random seed for CNTK components\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует два режима работы:\n",
    "- *Быстрый режим*: `isFast` установлен на `True`. Это режим по умолчанию для ноутбуков, что означает, что мы тренируемся за меньшее количество итераций по ограниченным данным. Это обеспечивает функциональную корректность ноутбука, хотя выпущенные модели далеки от того, что могло бы произвести завершенное обучение.\n",
    "\n",
    "- *Медленный режим*:  мы рекомендуем пользователю установить этот флаг в значение `False` , как только пользователь изучит ноутбук, и хочет получить представление о работе ноутбуков в течение более длительного периода с различными параметрами для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isFast = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чтение данных\n",
    "\n",
    "В этом разделе мы будем читать данные, сгенерированные в CNTK 103 Part A.\n",
    "\n",
    "Данные находятся в следующем формате:\n",
    "\n",
    "    |labels 0 0 0 0 0 0 0 1 0 0 |features 0 0 0 0 ... \n",
    "                                                  (784 integers each representing a pixel)\n",
    "    \n",
    " В этом уроке мы будем использовать пиксели изображения, соответствующие целочисленному потоку с именем \"features\". Мы определяем функцию  `create_reader` для чтения данных обучения и тестирования с помощью [CTF deserializer](https://cntk.ai/pythondocs/cntk.io.html?highlight=ctfdeserializer#cntk.io.CTFDeserializer). Метки [1-hot encoded](https://en.wikipedia.org/wiki/One-hot). Мы игнорируем их в этом уроке. \n",
    "\n",
    "Мы также проверяем, загружен ли файл обучения и тестовых данных для чтения функцией `create_reader`. В этом уроке мы используем данные MNIST, которые вы загрузили, используя ноутбук CNTK_103A_MNIST_DataLoader. Набор данных содержит 60 000 обучающих изображений и 10 000 тестовых изображений, каждое изображение которых составляет 28 х 28 пикселей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read a CTF formatted text (as mentioned above) using the CTF deserializer from a file\n",
    "def create_reader(path, is_training, input_dim, num_label_classes):\n",
    "    return C.io.MinibatchSource(C.io.CTFDeserializer(path, C.io.StreamDefs(\n",
    "        labels_viz = C.io.StreamDef(field='labels', shape=num_label_classes, is_sparse=False),\n",
    "        features   = C.io.StreamDef(field='features', shape=input_dim, is_sparse=False)\n",
    "    )), randomize = is_training, max_sweeps = C.io.INFINITELY_REPEAT if is_training else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory is data\\MNIST\n"
     ]
    }
   ],
   "source": [
    "# Ensure the training and test data is generated and available for this tutorial.\n",
    "# We search in two locations in the toolkit for the cached MNIST data set.\n",
    "data_found = False\n",
    "for data_dir in [os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\"),\n",
    "                 os.path.join(\"data\", \"MNIST\")]:\n",
    "    train_file = os.path.join(data_dir, \"Train-28x28_cntk_text.txt\")\n",
    "    test_file = os.path.join(data_dir, \"Test-28x28_cntk_text.txt\")\n",
    "    if os.path.isfile(train_file) and os.path.isfile(test_file):\n",
    "        data_found = True\n",
    "        break\n",
    "        \n",
    "if not data_found:\n",
    "    raise ValueError(\"Please generate the data by completing CNTK 103 Part A\")\n",
    "print(\"Data directory is {0}\".format(data_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание модели (Простой AE)\n",
    "\n",
    "Мы начинаем с простой единой полностью подключенной сети прямого доступа в качестве энкодера и в качестве декодера (как показано на рисунке ниже):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://cntk.ai/jup/SimpleAEfig.jpg\" width=\"200\" height=\"200\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Рисунок 2\n",
    "Image(url=\"http://cntk.ai/jup/SimpleAEfig.jpg\", width=200, height=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Входные данные представляют собой набор ручных цифровых изображений, каждый из которых 28 х 28 пикселей. В этом уроке мы рассмотрим каждое изображение как линейный массив из 784 пиксельных значений. Эти пиксели рассматриваются как вход с 784 размерами, по одному на пиксель. Поскольку целью автокодера является сжатие данных и восстановление исходного изображения, выходной размер такой же, как и размер входного сигнала. Мы сжимаем входные данные до 32 измерений (называемых `encoding_dim`). Кроме того, поскольку максимальное входное значение равно 255, мы нормируем вход между 0 и 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "encoding_dim = 32\n",
    "output_dim = input_dim\n",
    "\n",
    "def create_model(features):\n",
    "    with C.layers.default_options(init = C.glorot_uniform()):\n",
    "        # We scale the input pixels to 0-1 range\n",
    "        encode = C.layers.Dense(encoding_dim, activation = C.relu)(features/255.0)\n",
    "        decode = C.layers.Dense(input_dim, activation = C.sigmoid)(encode)\n",
    "\n",
    "    return decode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение и тестирование модели\n",
    "\n",
    "В предыдущих уроках мы определили каждую фазу обучения и тестирования отдельно. В этом уроке мы объединяем два компонента в одном месте, чтобы этот шаблон можно было использовать в качестве примера для использования.  \n",
    "\n",
    "Функция `train_and_test`выполняет две основные задачи:\n",
    "- Обучить модель\n",
    "- Оценить точность модели по тестовым данным\n",
    "\n",
    "Для тренировки:\n",
    "\n",
    "> Функция принимает читателя (`reader_train`), модельную функцию (`model_func`)и целевую (a.k.a `label`) в качестве входных данных. В этом уроке мы покажем, как создать и передать **own**  свою функцию потери.  Мы нормализуем функцию `label`, чтобы иполучать значение между 0 и 1 для вычисления ошибки метки с помощью функции `C.classification_error`.\n",
    "\n",
    "> Мы используем оптимизатор Adam [learners](https://www.cntk.ai/pythondocs/cntk.learner.html#module-cntk.learner) в этом учебном пособии из ряда доступных в наборе инструментов.  \n",
    "\n",
    "Для тестирования:\n",
    "\n",
    "> Функция дополнительно берет считыватель (`reader_test`) и оценивает предсказанные значения пикселей, сделанные моделью по сравнению с эталонными данными, в этом случае исходные значения пикселей для каждого изображения.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_test(reader_train, reader_test, model_func):\n",
    "    \n",
    "    ###############################################\n",
    "    # Training the model\n",
    "    ###############################################\n",
    "    \n",
    "    # Instantiate the input and the label variables\n",
    "    input = C.input_variable(input_dim)\n",
    "    label = C.input_variable(input_dim)\n",
    "    \n",
    "    # Create the model function\n",
    "    model = model_func(input)\n",
    "    \n",
    "    # The labels for this network is same as the input MNIST image.\n",
    "    # Note: Inside the model we are scaling the input to 0-1 range\n",
    "    # Hence we rescale the label to the same range\n",
    "    # We show how one can use their custom loss function\n",
    "    # loss = -(y* log(p)+ (1-y) * log(1-p)) where p = model output and y = target\n",
    "    # We have normalized the input between 0-1. Hence we scale the target to same range\n",
    "    \n",
    "    target = label/255.0 \n",
    "    loss = -(target * C.log(model) + (1 - target) * C.log(1 - model))\n",
    "    label_error  = C.classification_error(model, target)\n",
    "    \n",
    "    # training config\n",
    "    epoch_size = 30000        # 30000 samples is half the dataset size \n",
    "    minibatch_size = 64\n",
    "    num_sweeps_to_train_with = 5 if isFast else 100\n",
    "    num_samples_per_sweep = 60000\n",
    "    num_minibatches_to_train = (num_samples_per_sweep * num_sweeps_to_train_with) // minibatch_size\n",
    " \n",
    "    \n",
    "    # Instantiate the trainer object to drive the model training\n",
    "    lr_per_sample = [0.00003]\n",
    "    lr_schedule = C.learning_rate_schedule(lr_per_sample, C.UnitType.sample, epoch_size)\n",
    "    \n",
    "    # Momentum\n",
    "    momentum_as_time_constant = C.momentum_as_time_constant_schedule(700)\n",
    "    \n",
    "    # We use a variant of the Adam optimizer which is known to work well on this dataset\n",
    "    # Feel free to try other optimizers from \n",
    "    # https://www.cntk.ai/pythondocs/cntk.learner.html#module-cntk.learner\n",
    "    learner = C.fsadagrad(model.parameters,\n",
    "                         lr=lr_schedule, momentum=momentum_as_time_constant) \n",
    "    \n",
    "    # Instantiate the trainer\n",
    "    progress_printer = C.logging.ProgressPrinter(0)\n",
    "    trainer = C.Trainer(model, (loss, label_error), learner, progress_printer)\n",
    "    \n",
    "    # Map the data streams to the input and labels.\n",
    "    # Note: for autoencoders input == label\n",
    "    input_map = {\n",
    "        input  : reader_train.streams.features,\n",
    "        label  : reader_train.streams.features\n",
    "    } \n",
    "    \n",
    "    aggregate_metric = 0\n",
    "    for i in range(num_minibatches_to_train):\n",
    "        # Read a mini batch from the training data file\n",
    "        data = reader_train.next_minibatch(minibatch_size, input_map = input_map)\n",
    "        \n",
    "        # Run the trainer on and perform model training\n",
    "        trainer.train_minibatch(data)\n",
    "        samples = trainer.previous_minibatch_sample_count\n",
    "        aggregate_metric += trainer.previous_minibatch_evaluation_average * samples\n",
    "        \n",
    "    train_error = (aggregate_metric*100.0) / (trainer.total_number_of_samples_seen)\n",
    "    print(\"Average training error: {0:0.2f}%\".format(train_error))\n",
    "        \n",
    "    #############################################################################\n",
    "    # Testing the model\n",
    "    # Note: we use a test file reader to read data different from a training data\n",
    "    #############################################################################\n",
    "        \n",
    "    # Test data for trained model\n",
    "    test_minibatch_size = 32\n",
    "    num_samples = 10000\n",
    "    num_minibatches_to_test = num_samples / test_minibatch_size\n",
    "    test_result = 0.0\n",
    "    \n",
    "    # Test error metric calculation\n",
    "    metric_numer    = 0\n",
    "    metric_denom    = 0\n",
    "\n",
    "    test_input_map = {\n",
    "        input  : reader_test.streams.features,\n",
    "        label  : reader_test.streams.features\n",
    "    }\n",
    "\n",
    "    for i in range(0, int(num_minibatches_to_test)):\n",
    "        \n",
    "        # We are loading test data in batches specified by test_minibatch_size\n",
    "        # Each data point in the minibatch is a MNIST digit image of 784 dimensions \n",
    "        # with one pixel per dimension that we will encode / decode with the \n",
    "        # trained model.\n",
    "        data = reader_test.next_minibatch(test_minibatch_size,\n",
    "                                       input_map = test_input_map)\n",
    "\n",
    "        # Specify the mapping of input variables in the model to actual\n",
    "        # minibatch data to be tested with\n",
    "        eval_error = trainer.test_minibatch(data)\n",
    "        \n",
    "        # minibatch data to be trained with\n",
    "        metric_numer += np.abs(eval_error * test_minibatch_size)\n",
    "        metric_denom += test_minibatch_size\n",
    "\n",
    "    # Average of evaluation errors of all test minibatches\n",
    "    test_error = (metric_numer*100.0) / (metric_denom) \n",
    "    print(\"Average test error: {0:0.2f}%\".format(test_error))\n",
    "    \n",
    "    return model, train_error, test_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обучем простой автокодер. Мы создаем учебный и тестовый читатель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per 1 samples: 3e-05\n",
      "      544        544      0.877      0.877            64\n",
      "      544        544      0.866       0.86           192\n",
      "      544        543      0.869      0.871           448\n",
      "      542        541      0.869      0.868           960\n",
      "      538        533       0.84      0.813          1984\n",
      "      496        455      0.731      0.625          4032\n",
      "      385        276      0.566      0.404          8128\n",
      "      303        221       0.44      0.315         16320\n",
      "      250        197      0.341      0.242         32704\n",
      "      208        167      0.258      0.175         65472\n",
      "      173        138      0.183      0.107        131008\n",
      "      142        110      0.116     0.0495        262080\n",
      "Average training error: 10.57%\n",
      "Average test error: 3.04%\n"
     ]
    }
   ],
   "source": [
    "num_label_classes = 15\n",
    "reader_train = create_reader(train_file, True, input_dim, num_label_classes)\n",
    "reader_test = create_reader(test_file, False, input_dim, num_label_classes)\n",
    "model, simple_ae_train_error, simple_ae_test_error = train_and_test(reader_train, \n",
    "                                                                    reader_test, \n",
    "                                                                    model_func = create_model )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализируем простые результаты AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image statistics:\n",
      "Max: 255.00, Median: 0.00, Mean: 24.07, Min: 0.00\n",
      "Decoded image statistics:\n",
      "Max: 251.79, Median: 0.43, Mean: 26.11, Min: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Read some data to run the eval\n",
    "num_label_classes = 10\n",
    "reader_eval = create_reader(test_file, False, input_dim, num_label_classes)\n",
    "\n",
    "eval_minibatch_size = 50\n",
    "eval_input_map = { input  : reader_eval.streams.features }    \n",
    "    \n",
    "eval_data = reader_eval.next_minibatch(eval_minibatch_size,\n",
    "                                  input_map = eval_input_map)\n",
    "\n",
    "img_data = eval_data[input].asarray()\n",
    "\n",
    "# Select a random image\n",
    "np.random.seed(0) \n",
    "idx = np.random.choice(eval_minibatch_size)\n",
    "\n",
    "orig_image = img_data[idx,:,:]\n",
    "decoded_image = model.eval(orig_image)[0]*255\n",
    "\n",
    "# Print image statistics\n",
    "def print_image_stats(img, text):\n",
    "    print(text)\n",
    "    print(\"Max: {0:.2f}, Median: {1:.2f}, Mean: {2:.2f}, Min: {3:.2f}\".format(np.max(img),\n",
    "                                                                              np.median(img),\n",
    "                                                                              np.mean(img),\n",
    "                                                                              np.min(img))) \n",
    "    \n",
    "# Print original image\n",
    "print_image_stats(orig_image, \"Original image statistics:\")\n",
    "\n",
    "# Print decoded image\n",
    "print_image_stats(decoded_image, \"Decoded image statistics:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим оригинальное и декодированное изображение. Они должны выглядеть визуально одинаковыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a helper function to plot a pair of images\n",
    "def plot_image_pair(img1, text1, img2, text2):\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(6, 6))\n",
    "\n",
    "    axes[0].imshow(img1, cmap=\"gray\")\n",
    "    axes[0].set_title(text1)\n",
    "    axes[0].axis(\"off\")\n",
    "\n",
    "    axes[1].imshow(img2, cmap=\"gray\")\n",
    "    axes[1].set_title(text2)\n",
    "    axes[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADHCAYAAAAJSqg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23752dd2780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the original and the decoded image\n",
    "img1 = orig_image.reshape(28,28)\n",
    "text1 = 'Original image'\n",
    "\n",
    "img2 = decoded_image.reshape(28,28)\n",
    "text2 = 'Decoded image'\n",
    "\n",
    "plot_image_pair(img1, text1, img2, text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Создание модели (Deep AE)\n",
    "\n",
    "Нам не нужно ограничиваться одним слоем как кодер или декодер, вместо этого мы могли бы использовать стек плотных слоев. Создадим глубокий автокодер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://cntk.ai/jup/DeepAEfig.jpg\" width=\"500\" height=\"300\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Рисунок 3\n",
    "Image(url=\"http://cntk.ai/jup/DeepAEfig.jpg\", width=500, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Размеры кодирования составляют 128, 64 и 32, в то время как размеры декодирования симметрично противоположны 64, 128 и 784. Это увеличивает количество параметров, используемых для моделирования преобразования, и обеспечивает более низкие частоты ошибок за счет более длительной продолжительности обучения и объема памяти. Если мы будем обучать этот глубокий энкодер для большего числа итераций, повернув флаг `isFast` как `False`, мы получим более низкую ошибку, а восстановленные изображения также немного лучше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = 784\n",
    "encoding_dims = [128,64,32]\n",
    "decoding_dims = [64,128]\n",
    "\n",
    "encoded_model = None\n",
    "\n",
    "def create_deep_model(features):\n",
    "    with C.layers.default_options(init = C.layers.glorot_uniform()):\n",
    "        encode = C.element_times(C.constant(1.0/255.0), features)\n",
    "\n",
    "        for encoding_dim in encoding_dims:\n",
    "            encode = C.layers.Dense(encoding_dim, activation = C.relu)(encode)\n",
    "\n",
    "        global encoded_model\n",
    "        encoded_model= encode\n",
    "        \n",
    "        decode = encode\n",
    "        for decoding_dim in decoding_dims:\n",
    "            decode = C.layers.Dense(decoding_dim, activation = C.relu)(decode)\n",
    "\n",
    "        decode = C.layers.Dense(input_dim, activation = C.sigmoid)(decode)\n",
    "        return decode  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " average      since    average      since      examples\n",
      "    loss       last     metric       last              \n",
      " ------------------------------------------------------\n",
      "Learning rate per 1 samples: 3e-05\n",
      "      544        544       0.75       0.75            64\n",
      "      544        544      0.771      0.781           192\n",
      "      544        543       0.78      0.786           448\n",
      "      543        542      0.789      0.797           960\n",
      "      530        518      0.863      0.933          1984\n",
      "      415        303       0.77      0.679          4032\n",
      "      315        216      0.624       0.48          8128\n",
      "      258        203        0.5      0.376         16320\n",
      "      215        171      0.366      0.234         32704\n",
      "      176        137      0.251      0.136         65472\n",
      "      145        115      0.165     0.0782        131008\n",
      "      122       98.8      0.107     0.0486        262080\n",
      "Average training error: 9.78%\n",
      "Average test error: 3.19%\n"
     ]
    }
   ],
   "source": [
    "num_label_classes = 15\n",
    "reader_train = create_reader(train_file, True, input_dim, num_label_classes)\n",
    "reader_test = create_reader(test_file, False, input_dim, num_label_classes)\n",
    "\n",
    "model, deep_ae_train_error, deep_ae_test_error = train_and_test(reader_train, \n",
    "                                                                reader_test, \n",
    "                                                                model_func = create_deep_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация результатов глубокого AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original image statistics:\n",
      "Max: 255.00, Median: 0.00, Mean: 24.07, Min: 0.00\n",
      "Decoded image statistics:\n",
      "Max: 250.87, Median: 0.03, Mean: 24.76, Min: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Run the same image as the simple autoencoder through the deep encoder\n",
    "orig_image = img_data[idx,:,:]\n",
    "decoded_image = model.eval(orig_image)[0]*255\n",
    "\n",
    "# Print image statistics\n",
    "def print_image_stats(img, text):\n",
    "    print(text)\n",
    "    print(\"Max: {0:.2f}, Median: {1:.2f}, Mean: {2:.2f}, Min: {3:.2f}\".format(np.max(img),\n",
    "                                                                              np.median(img),\n",
    "                                                                              np.mean(img),\n",
    "                                                                              np.min(img))) \n",
    "    \n",
    "# Print original image\n",
    "print_image_stats(orig_image, \"Original image statistics:\")\n",
    "\n",
    "# Print decoded image\n",
    "print_image_stats(decoded_image, \"Decoded image statistics:\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте построим оригинальное и декодированное изображение с помощью глубокого автокодера. Они должны выглядеть визуально одинаковыми."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADHCAYAAAAJSqg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBDoARIJAB4BIEOgAEAkCHQAi8f8JycQTvQGR3AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23754fefa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the original and the decoded image\n",
    "img1 = orig_image.reshape(28,28)\n",
    "text1 = 'Original image'\n",
    "\n",
    "img2 = decoded_image.reshape(28,28)\n",
    "text2 = 'Decoded image'\n",
    "\n",
    "plot_image_pair(img1, text1, img2, text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы показали, как кодировать и декодировать ввод. В этом разделе мы рассмотрим как мы можем сравнивать друг с другом, а также как извлечь закодированный вход для данного ввода. Для визуализации высокоразмерных данных в 2D, [t-SNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) вероятно, является одним из лучших методов. Однако для этого обычно требуются относительно низкоразмерные данные. Поэтому хорошей стратегией визуализации отношений подобия в высокоразмерных данных является кодирование данных в низкоразмерном пространстве (например, 32-мерное) с использованием автокодера сначала, извлечение кодировки входных данных с последующим использованием t-SNE  для отображения сжатых данных в двумерную плоскость. \n",
    "\n",
    "Мы будем использовать выходы глубокого автокодера:\n",
    "- Сравнивать два изображения и\n",
    "- Показыватьь, как мы можем получить закодированные (сжатые) данные.\n",
    "\n",
    "Сначала нам нужно прочитать некоторые данные изображения вместе с их метками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read some data to run get the image data and the corresponding labels\n",
    "num_label_classes = 10\n",
    "reader_viz = create_reader(test_file, False, input_dim, num_label_classes)\n",
    "\n",
    "image = C.input_variable(input_dim)\n",
    "image_label = C.input_variable(num_label_classes)\n",
    "\n",
    "viz_minibatch_size = 50\n",
    "\n",
    "viz_input_map = { \n",
    "    image  : reader_viz.streams.features, \n",
    "    image_label  : reader_viz.streams.labels_viz \n",
    "}    \n",
    "    \n",
    "viz_data = reader_eval.next_minibatch(viz_minibatch_size,\n",
    "                                  input_map = viz_input_map)\n",
    "\n",
    "img_data   = viz_data[image].asarray()\n",
    "imglabel_raw = viz_data[image_label].asarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: [7, 24, 39, 44, 46]\n",
      "3: [1, 13, 18, 26, 37, 40, 43]\n",
      "9: [8, 12, 23, 28, 42, 49]\n"
     ]
    }
   ],
   "source": [
    "# Map the image labels into indices in minibatch array\n",
    "img_labels = [np.argmax(imglabel_raw[i,:,:]) for i in range(0, imglabel_raw.shape[0])]       \n",
    "        \n",
    "from collections import defaultdict\n",
    "label_dict=defaultdict(list)\n",
    "for img_idx, img_label, in enumerate(img_labels):\n",
    "    label_dict[img_label].append(img_idx)        \n",
    "    \n",
    "# Print indices corresponding to 3 digits\n",
    "randIdx = [1, 3, 9]\n",
    "for i in randIdx:\n",
    "    print(\"{0}: {1}\".format(i, label_dict[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will [compute cosine distance](https://en.wikipedia.org/wiki/Cosine_similarity) between two images using `scipy`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "\n",
    "def image_pair_cosine_distance(img1, img2):\n",
    "    if img1.size != img2.size:\n",
    "        raise ValueError(\"Two images need to be of same dimension\")\n",
    "    return 1 - spatial.distance.cosine(img1, img2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between two original image: 0.294\n",
      "Distance between two decoded image: 0.328\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADHCAYAAAAJSqg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23753513978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADHCAYAAAAJSqg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBAUdABLxf2oitvVHb0F+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2375369e0b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let s compute the distance between two images of the same number\n",
    "digit_of_interest = 6\n",
    "\n",
    "digit_index_list = label_dict[digit_of_interest]\n",
    "\n",
    "if len(digit_index_list) < 2:\n",
    "    print(\"Need at least two images to compare\")\n",
    "else:\n",
    "    imgA = img_data[digit_index_list[0],:,:][0] \n",
    "    imgB = img_data[digit_index_list[1],:,:][0]\n",
    "    \n",
    "    # Print distance between original image\n",
    "    imgA_B_dist = image_pair_cosine_distance(imgA, imgB)\n",
    "    print(\"Distance between two original image: {0:.3f}\".format(imgA_B_dist))\n",
    "    \n",
    "    # Plot the two images\n",
    "    img1 = imgA.reshape(28,28)\n",
    "    text1 = 'Original image 1'\n",
    "\n",
    "    img2 = imgB.reshape(28,28)\n",
    "    text2 = 'Original image 2'\n",
    "\n",
    "    plot_image_pair(img1, text1, img2, text2)\n",
    "    \n",
    "    # Decode the encoded stream \n",
    "    imgA_decoded =  model.eval([imgA])[0]\n",
    "    imgB_decoded =  model.eval([imgB])   [0]    \n",
    "    imgA_B_decoded_dist = image_pair_cosine_distance(imgA_decoded, imgB_decoded)\n",
    "\n",
    "    # Print distance between original image\n",
    "    print(\"Distance between two decoded image: {0:.3f}\".format(imgA_B_decoded_dist))\n",
    "    \n",
    "    # Plot the two images\n",
    "    # Plot the original and the decoded image\n",
    "    img1 = imgA_decoded.reshape(28,28)\n",
    "    text1 = 'Decoded image 1'\n",
    "\n",
    "    img2 = imgB_decoded.reshape(28,28)\n",
    "    text2 = 'Decoded image 2'\n",
    "\n",
    "    plot_image_pair(img1, text1, img2, text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примечание: Косинус расстояние между исходными изображениями, сравнимыми с расстоянием между соответствующими декодированными изображениями. Значение 1 указывает на высокое сходство между изображениями и 0 означает отсутствие сходства.\n",
    "\n",
    "Давайте посмотрим, как получить кодированный вектор, соответствующий входному изображению. Это должно иметь размер точки заслонки в сети, показанной на рисунке, с полем, обозначенным буквой `E`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the original image is 784 and the encoded image is  32\n",
      "\n",
      "The encoded image: \n",
      "[ 11.82777977   4.2463069    9.04645538   8.06909943   0.          12.10138416\n",
      "  24.50163841  22.81308746  17.6485424    0.           0.          25.21560097\n",
      "  17.95014191  15.85327148  14.81459904  13.8848505   20.05287933\n",
      "  15.64199352   5.09397745  19.44846725   9.97392941  25.279356\n",
      "  14.46046925  11.2520628    8.5930748    0.          11.51117039\n",
      "  18.61786079   8.75617695  13.50009632  15.16327667  15.76924419]\n"
     ]
    }
   ],
   "source": [
    "imgA = img_data[digit_index_list[0],:,:][0] \n",
    "imgA_encoded =  encoded_model.eval([imgA])\n",
    "\n",
    "print(\"Length of the original image is {0:3d} and the encoded image is {1:3d}\".format(len(imgA), \n",
    "                                                                                      len(imgA_encoded[0])))\n",
    "print(\"\\nThe encoded image: \")\n",
    "print(imgA_encoded[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сравним расстояние между разными цифрами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between two original image: 0.376\n",
      "Distance between two decoded image: 0.398\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADHCAYAAAAJSqg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2375369e080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAADHCAYAAAAJSqg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2vh69ArWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23754fef940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digitA = 3\n",
    "digitB = 8\n",
    "\n",
    "digitA_index = label_dict[digitA]\n",
    "digitB_index = label_dict[digitB]\n",
    "\n",
    "imgA = img_data[digitA_index[0],:,:][0] \n",
    "imgB = img_data[digitB_index[0],:,:][0]\n",
    "\n",
    "# Print distance between original image\n",
    "imgA_B_dist = image_pair_cosine_distance(imgA, imgB)\n",
    "print(\"Distance between two original image: {0:.3f}\".format(imgA_B_dist))\n",
    "    \n",
    "# Plot the two images\n",
    "img1 = imgA.reshape(28,28)\n",
    "text1 = 'Original image 1'\n",
    "\n",
    "img2 = imgB.reshape(28,28)\n",
    "text2 = 'Original image 2'\n",
    "\n",
    "plot_image_pair(img1, text1, img2, text2)\n",
    "    \n",
    "# Decode the encoded stream \n",
    "imgA_decoded =  model.eval([imgA])[0]\n",
    "imgB_decoded =  model.eval([imgB])[0]    \n",
    "imgA_B_decoded_dist = image_pair_cosine_distance(imgA_decoded, imgB_decoded)\n",
    "\n",
    "#Print distance between original image\n",
    "print(\"Distance between two decoded image: {0:.3f}\".format(imgA_B_decoded_dist))\n",
    "\n",
    "# Plot the original and the decoded image\n",
    "img1 = imgA_decoded.reshape(28,28)\n",
    "text1 = 'Decoded image 1'\n",
    "\n",
    "img2 = imgB_decoded.reshape(28,28)\n",
    "text2 = 'Decoded image 2'\n",
    "\n",
    "plot_image_pair(img1, text1, img2, text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Распечатайте результаты тестовой ошибки глубокого кодирования для регрессионного тестирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0350973549\n"
     ]
    }
   ],
   "source": [
    "# Simple autoencoder test error\n",
    "print(simple_ae_test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.19201508\n"
     ]
    }
   ],
   "source": [
    "# Deep autoencoder test error\n",
    "print(deep_ae_test_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дополнительные задания**\n",
    "\n",
    "- Попробуйте различные функции активации.\n",
    "- Найдите, какие изображения больше похожи друг на друга (a), используя оригинальное изображение и (b) декодированное изображение.\n",
    "- Попробуйте использовать среднюю квадратную ошибку в качестве функции потерь. Улучшает ли производительность кодировщик с точки зрения сокращения ошибок.\n",
    "- Можете ли вы попробовать другую структуру сети, чтобы еще больше уменьшить ошибку. Объясните свои наблюдения.\n",
    "- Можете ли вы использовать другую метрику расстояния для вычисления сходства между изображениями MNIST.\n",
    "- Попробуйте использовать глубокий кодировщик с [1000, 500, 250, 128, 64, 32]. Какова ошибка обучения для такого же количества итераций?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
